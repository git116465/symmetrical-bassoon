import json
from typing import List, Dict

def process_international_data() -> List[Dict]:
    """
    ä»Excelæ•°æ®ä¸­æå–ä¸–ç•Œå„å¤§æ´²ç³–å°¿ç—…ä¿¡æ¯
    """
    continent_data = [
        {
            "name": "äºšæ´²",
            "diabetes_rate": 60.0,
            "population": 4641,  # ç™¾ä¸‡
            "cases": 2785,      # ç™¾ä¸‡
            "countries": 48,
            "summary": "äºšæ´²æ˜¯å…¨çƒç³–å°¿ç—…æ‚£ç—…ç‡æœ€é«˜çš„åœ°åŒºï¼Œä¸»è¦ç”±äºäººå£åŸºæ•°å¤§ã€é¥®é£Ÿä¹ æƒ¯æ”¹å˜å’ŒåŸå¸‚åŒ–è¿›ç¨‹åŠ å¿«",
            "trend": "rising",
            "risk_factors": ["é¥®é£Ÿä¹ æƒ¯è¥¿æ–¹åŒ–", "ç¼ºä¹è¿åŠ¨", "è‚¥èƒ–ç‡ä¸Šå‡", "é—ä¼ å› ç´ "]
        },
        {
            "name": "éæ´²",
            "diabetes_rate": 10.5,
            "population": 1370,
            "cases": 144,
            "countries": 54,
            "summary": "éæ´²ç³–å°¿ç—…æ‚£ç—…ç‡ç›¸å¯¹è¾ƒä½ä½†å¢é•¿è¿…é€Ÿï¼ŒåŒ»ç–—èµ„æºåŒ®ä¹æ˜¯ä¸»è¦æŒ‘æˆ˜",
            "trend": "rapidly_rising",
            "risk_factors": ["åŸå¸‚åŒ–", "é¥®é£Ÿå˜åŒ–", "åŒ»ç–—æ¡ä»¶æœ‰é™", "å¥åº·æ„è¯†ä¸è¶³"]
        },
        {
            "name": "å¤§æ´‹æ´²",
            "diabetes_rate": 12.3,
            "population": 43,
            "cases": 5.3,
            "countries": 14,
            "summary": "å¤§æ´‹æ´²åœ°åŒºç³–å°¿ç—…æ‚£ç—…ç‡è¾ƒé«˜ï¼Œç‰¹åˆ«æ˜¯æ¾³å¤§åˆ©äºšå’Œæ–°è¥¿å…°çš„åœŸè‘—äººç¾¤",
            "trend": "stable",
            "risk_factors": ["è‚¥èƒ–é—®é¢˜", "åœŸè‘—äººç¾¤é—ä¼ æ˜“æ„Ÿæ€§", "ç”Ÿæ´»æ–¹å¼å˜åŒ–"]
        },
        {
            "name": "åŒ—ç¾æ´²",
            "diabetes_rate": 10.4,
            "population": 592,
            "cases": 61.6,
            "countries": 23,
            "summary": "åŒ—ç¾æ´²ç³–å°¿ç—…æ‚£ç—…ç‡è¾ƒé«˜ï¼Œç¾å›½æ˜¯ç³–å°¿ç—…å¤§å›½ï¼Œä½†è¿‘å¹´æ¥é˜²æ§æªæ–½æœ‰æ‰€æˆæ•ˆ",
            "trend": "slowly_rising",
            "risk_factors": ["é«˜ç³–é¥®é£Ÿ", "ä¹…åç”Ÿæ´»æ–¹å¼", "è‚¥èƒ– epidemic", "è€é¾„åŒ–"]
        },
        {
            "name": "å—ç¾æ´²",
            "diabetes_rate": 9.4,
            "population": 434,
            "cases": 40.8,
            "countries": 12,
            "summary": "å—ç¾æ´²ç³–å°¿ç—…æ‚£ç—…ç‡ä¸­ç­‰ï¼Œä½†åŸå¸‚åŒ–è¿›ç¨‹å¯¼è‡´æ‚£ç—…ç‡æŒç»­ä¸Šå‡",
            "trend": "rising",
            "risk_factors": ["åŸå¸‚åŒ–", "é¥®é£Ÿç»“æ„å˜åŒ–", "ç»æµå¿«é€Ÿå‘å±•", "å¥åº·æœåŠ¡ä¸å‡"]
        },
        {
            "name": "æ¬§æ´²",
            "diabetes_rate": 8.1,
            "population": 747,
            "cases": 60.5,
            "countries": 44,
            "summary": "æ¬§æ´²ç³–å°¿ç—…æ‚£ç—…ç‡ç›¸å¯¹è¾ƒä½ä½†æŒç»­å¢é•¿ï¼Œä¸œæ¬§åœ°åŒºæ‚£ç—…ç‡é«˜äºè¥¿æ¬§",
            "trend": "slowly_rising",
            "risk_factors": ["è€é¾„åŒ–äººå£", "è‚¥èƒ–é—®é¢˜", "ç”Ÿæ´»æ–¹å¼", "ä¸œæ¬§ç»æµè½¬å‹å½±å“"]
        },
        {
            "name": "å—ææ´²",
            "diabetes_rate": None,
            "population": 0.004,  # ç§‘ç ”äººå‘˜
            "cases": None,
            "countries": 0,
            "summary": "å—ææ´²æ— å¸¸ä½äººå£ï¼Œä»…æœ‰ç§‘ç ”äººå‘˜ä¸´æ—¶å±…ä½ï¼Œæ— ç³–å°¿ç—…ç»Ÿè®¡èµ„æ–™",
            "trend": "unknown",
            "risk_factors": ["æç«¯ç¯å¢ƒ", "ç‰¹æ®Šé¥®é£Ÿ", "ç§‘ç ”å·¥ä½œå‹åŠ›"],
            "note": "æ— å¸¸ä½äººå£ï¼Œæ•°æ®æš‚ç¼º"
        }
    ]
    
    return continent_data

def generate_international_data_json():
    """
    ç”Ÿæˆå®Œæ•´çš„international_data.jsonæ–‡ä»¶
    """
    continents = process_international_data()
    
    # è®¡ç®—ç»Ÿè®¡æ‘˜è¦
    valid_continents = [c for c in continents if c["diabetes_rate"] is not None]
    
    # æ„å»ºå®Œæ•´çš„JSONç»“æ„
    international_data = {
        "metadata": {
            "data_source": "ä¸–ç•Œæ•°æ®.xlsx",
            "last_updated": "2025-07-15",
            "total_continents": len(valid_continents),
            "rate_unit": "percentage",
            "population_unit": "ç™¾ä¸‡äºº",
            "cases_unit": "ç™¾ä¸‡äºº"
        },
        "summary": {
            "total_population": sum(continent["population"] for continent in valid_continents),
            "total_cases": sum(continent["cases"] for continent in valid_continents if continent["cases"] is not None),
            "avg_diabetes_rate": round(sum(continent["diabetes_rate"] for continent in valid_continents) / len(valid_continents), 1),
            "total_countries": sum(continent["countries"] for continent in valid_continents),
            "highest_rate_continent": max(valid_continents, key=lambda x: x["diabetes_rate"])["name"],
            "lowest_rate_continent": min(valid_continents, key=lambda x: x["diabetes_rate"])["name"]
        },
        "continents": continents,
        "global_trends": {
            "years": [2010, 2015, 2020, 2025],
            "global_rates": [8.4, 9.2, 10.5, 11.3],
            "trend_description": "å…¨çƒç³–å°¿ç—…æ‚£ç—…ç‡æŒç»­ä¸Šå‡ï¼Œé¢„è®¡åˆ°2045å¹´å°†æœ‰7äº¿ç³–å°¿ç—…æ‚£è€…"
        },
        "risk_levels": [
            {"level": "high", "range": ">10%", "continents": ["äºšæ´²", "éæ´²", "å¤§æ´‹æ´²", "åŒ—ç¾æ´²"]},
            {"level": "medium", "range": "5-10%", "continents": ["å—ç¾æ´²", "æ¬§æ´²"]},
            {"level": "low", "range": "<5%", "continents": []},
            {"level": "unknown", "range": "æ— æ•°æ®", "continents": ["å—ææ´²"]}
        ]
    }
    
    # ä¿å­˜ä¸ºJSONæ–‡ä»¶
    with open('data/international_data.json', 'w', encoding='utf-8') as f:
        json.dump(international_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… æˆåŠŸç”Ÿæˆ international_data.json")
    print(f"ğŸŒ åŒ…å« {len(continents)} ä¸ªå¤§æ´²æ•°æ®")
    print(f"ğŸ‘¥ æ€»äººå£: {international_data['summary']['total_population']} ç™¾ä¸‡")
    print(f"ğŸ©º æ€»ç—…ä¾‹æ•°: {international_data['summary']['total_cases']} ç™¾ä¸‡")
    print(f"ğŸ“ˆ å¹³å‡æ‚£ç—…ç‡: {international_data['summary']['avg_diabetes_rate']}%")
    print(f"ğŸ† æœ€é«˜æ‚£ç—…ç‡: {international_data['summary']['highest_rate_continent']}")
    print(f"ğŸ“‰ æœ€ä½æ‚£ç—…ç‡: {international_data['summary']['lowest_rate_continent']}")
    
    return international_data

def update_data_loader_for_international():
    """
    æ›´æ–°æ•°æ®åŠ è½½å™¨ä»¥æ”¯æŒå›½é™…æ•°æ®
    """
    loader_code = '''import json
import os

def load_china_data():
    """åŠ è½½ä¸­å›½çœä»½ç³–å°¿ç—…æ•°æ®"""
    data_path = os.path.join(os.path.dirname(__file__), '..', 'data', 'china_data.json')
    try:
        with open(data_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            
            # ä¸ºå‰ç«¯æä¾›ç®€åŒ–æ ¼å¼
            simplified_provinces = []
            for province in data['provinces']:
                simplified_provinces.append({
                    'name': province['name'],
                    'diabetes_rate': province['total_rate'],
                    'population': province['population'],
                    'cases': province['cases'],
                    'male_rate': province['male_rate'],
                    'female_rate': province['female_rate']
                })
            
            return {
                'provinces': simplified_provinces,
                'metadata': data['metadata'],
                'summary': data['summary'],
                'regions': data['regions']
            }
            
    except FileNotFoundError:
        # è¿”å›ç¤ºä¾‹æ•°æ®
        return {
            "provinces": [
                {"name": "åŒ—äº¬", "diabetes_rate": 8.5, "population": 2154, "cases": 183},
                {"name": "ä¸Šæµ·", "diabetes_rate": 9.2, "population": 2428, "cases": 223},
            ],
            "metadata": {
                "data_source": "fallback",
                "last_updated": "2025-07-15"
            }
        }

def load_international_data():
    """åŠ è½½å›½é™…ç³–å°¿ç—…æ•°æ®"""
    data_path = os.path.join(os.path.dirname(__file__), '..', 'data', 'international_data.json')
    try:
        with open(data_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            
            # ä¸ºå‰ç«¯æä¾›ç®€åŒ–æ ¼å¼
            simplified_continents = []
            for continent in data['continents']:
                simplified_continents.append({
                    'name': continent['name'],
                    'diabetes_rate': continent['diabetes_rate'],
                    'population': continent['population'],
                    'cases': continent['cases'],
                    'countries': continent['countries']
                })
            
            return {
                'continents': simplified_continents,
                'metadata': data['metadata'],
                'summary': data['summary'],
                'global_trends': data['global_trends'],
                'risk_levels': data['risk_levels']
            }
            
    except FileNotFoundError:
        # è¿”å›ç¤ºä¾‹æ•°æ®
        return {
            "continents": [
                {"name": "äºšæ´²", "diabetes_rate": 60.0, "countries": 48},
                {"name": "æ¬§æ´²", "diabetes_rate": 6.2, "countries": 44},
            ],
            "metadata": {
                "data_source": "fallback",
                "last_updated": "2025-07-15"
            }
        }

def load_trends_data():
    """åŠ è½½è¶‹åŠ¿æ•°æ®"""
    data_path = os.path.join(os.path.dirname(__file__), '..', 'data', 'trends_data.json')
    try:
        with open(data_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        return {
            "years": [2010, 2015, 2020, 2025],
            "global_rates": [6.4, 7.2, 8.5, 9.2],
            "china_rates": [7.8, 8.6, 9.8, 10.6]
        }
'''
    
    with open('utils/data_loader.py', 'w', encoding='utf-8') as f:
        f.write(loader_code)
    
    print("âœ… å·²æ›´æ–°æ•°æ®åŠ è½½å™¨ï¼Œæ”¯æŒå›½é™…æ•°æ®")

# åˆ›å»ºç¤ºä¾‹è¶‹åŠ¿æ•°æ®æ–‡ä»¶
def create_trends_data_file():
    """åˆ›å»ºè¶‹åŠ¿æ•°æ®æ–‡ä»¶"""
    trends_data = {
        "metadata": {
            "data_source": "WHOå…¨çƒç³–å°¿ç—…æŠ¥å‘Š",
            "last_updated": "2025-07-15",
            "rate_unit": "percentage"
        },
        "global_trends": {
            "years": [1990, 2000, 2010, 2020, 2025, 2030, 2040, 2045],
            "rates": [4.7, 5.4, 6.4, 8.5, 9.2, 10.2, 11.3, 12.2],
            "projected_cases": [151, 171, 285, 463, 578, 643, 700, 783]  # ç™¾ä¸‡
        },
        "regional_trends": {
            "asia": {
                "years": [2010, 2015, 2020, 2025],
                "rates": [55.0, 57.0, 59.0, 60.0]
            },
            "europe": {
                "years": [2010, 2015, 2020, 2025],
                "rates": [7.2, 7.6, 7.9, 8.1]
            },
            "africa": {
                "years": [2010, 2015, 2020, 2025],
                "rates": [7.8, 8.9, 9.8, 10.5]
            }
        },
        "china_vs_global": {
            "years": [2010, 2015, 2020, 2025],
            "global_rates": [6.4, 7.2, 8.5, 9.2],
            "china_rates": [7.8, 8.6, 9.8, 10.6],
            "difference": [1.4, 1.4, 1.3, 1.4]
        }
    }
    
    with open('data/trends_data.json', 'w', encoding='utf-8') as f:
        json.dump(trends_data, f, ensure_ascii=False, indent=2)
    
    print("âœ… å·²ç”Ÿæˆè¶‹åŠ¿æ•°æ®æ–‡ä»¶")

if __name__ == "__main__":
    # ç”Ÿæˆå›½é™…æ•°æ®æ–‡ä»¶
    generate_international_data_json()
    
    # æ›´æ–°æ•°æ®åŠ è½½å™¨
    update_data_loader_for_international()
    
    # ç”Ÿæˆè¶‹åŠ¿æ•°æ®æ–‡ä»¶
    create_trends_data_file()
    
    print("\nğŸ‰ æ‰€æœ‰å›½é™…æ•°æ®æ–‡ä»¶å·²ç”Ÿæˆå®Œæˆï¼")
    print("ğŸ“ international_data.json å·²ä¿å­˜åˆ° data/ ç›®å½•")
    print("ğŸ“ trends_data.json å·²ä¿å­˜åˆ° data/ ç›®å½•")
    print("ğŸ“ data_loader.py å·²æ›´æ–°æ”¯æŒå›½é™…æ•°æ®")